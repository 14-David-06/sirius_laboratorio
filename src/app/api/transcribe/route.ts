import { NextRequest, NextResponse } from 'next/server';
import OpenAI from 'openai';

// Validar que la API key est√© presente y sea v√°lida
if (!process.env.OPENAI_API_KEY) {
  throw new Error('OPENAI_API_KEY environment variable is required');
}

if (!process.env.OPENAI_API_KEY.startsWith('sk-')) {
  throw new Error('OPENAI_API_KEY must be a valid OpenAI API key starting with sk-');
}

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

export async function POST(request: NextRequest) {
  try {
    console.log('üé§ TRANSCRIBE: Recibiendo solicitud de transcripci√≥n...');
    
    const formData = await request.formData();
    const audioFile = formData.get('audio') as File;

    if (!audioFile) {
      console.error('‚ùå TRANSCRIBE: No se recibi√≥ archivo de audio');
      return NextResponse.json(
        { success: false, error: 'No se recibi√≥ archivo de audio' },
        { status: 400 }
      );
    }

    console.log('üìÅ TRANSCRIBE: Archivo recibido:', {
      name: audioFile.name,
      size: audioFile.size,
      type: audioFile.type
    });

    // L√≠mite de tama√±o: 25MB (l√≠mite de OpenAI)
    const MAX_FILE_SIZE = 25 * 1024 * 1024; // 25MB
    if (audioFile.size > MAX_FILE_SIZE) {
      console.error('‚ùå TRANSCRIBE: Archivo demasiado grande:', audioFile.size);
      return NextResponse.json(
        { success: false, error: 'El archivo es demasiado grande. M√°ximo 25MB.' },
        { status: 400 }
      );
    }

    // Verificar que el archivo no est√© vac√≠o
    if (audioFile.size === 0) {
      console.error('‚ùå TRANSCRIBE: Archivo vac√≠o');
      return NextResponse.json(
        { success: false, error: 'El archivo de audio est√° vac√≠o' },
        { status: 400 }
      );
    }

    // Extraer tipo de archivo base (sin codecs como ;codecs=opus)
    const audioType = audioFile.type.split(';')[0];

    // Lista de tipos de archivo base permitidos (sin codecs)
    const allowedTypes = ['audio/webm', 'audio/wav', 'audio/mp3', 'audio/m4a', 'audio/ogg', 'audio/mp4'];
    
    if (!allowedTypes.includes(audioType)) {
      return NextResponse.json(
        { success: false, error: `Tipo de archivo no soportado: ${audioFile.type}` },
        { status: 400 }
      );
    }

    // Validaci√≥n adicional: rechazar codecs de WebM problem√°ticos
    if (audioFile.type.includes('audio/webm') && audioFile.type.includes('codecs=pcm')) {
      return NextResponse.json(
        { success: false, error: 'El formato WebM con codec PCM no es compatible. Por favor, usa otro formato.' },
        { status: 400 }
      );
    }

    // Rate limiting b√°sico por IP
    const clientIP = request.headers.get('x-forwarded-for') || 
                    request.headers.get('x-real-ip') || 
                    'unknown';
    
    console.log('üéôÔ∏è Solicitud de transcripci√≥n desde IP:', clientIP);
    console.log('üîä Archivo recibido:', {
      name: audioFile.name,
      size: audioFile.size,
      type: audioFile.type,
      timestamp: new Date().toISOString()
    });

    // Convertir File a formato que acepta OpenAI de forma segura
    const arrayBuffer = await audioFile.arrayBuffer();
    const buffer = Buffer.from(arrayBuffer);
    
    // Verificar que el buffer no est√© corrupto
    if (buffer.length !== audioFile.size) {
      return NextResponse.json(
        { success: false, error: 'Error al procesar el archivo de audio' },
        { status: 400 }
      );
    }
    
    // Crear un objeto File-like que OpenAI pueda procesar
    let fileName = 'audio.webm'; // Por defecto
    
    // Ajustar el nombre del archivo seg√∫n el tipo
    if (audioType === 'audio/mp4') fileName = 'audio.mp4';
    else if (audioType === 'audio/wav') fileName = 'audio.wav';
    else if (audioType === 'audio/mp3') fileName = 'audio.mp3';
    else if (audioType === 'audio/m4a') fileName = 'audio.m4a';
    else if (audioType === 'audio/ogg') fileName = 'audio.ogg';
    
    const file = new File([buffer], fileName, { type: audioType });

    console.log('Transcribiendo audio con OpenAI Whisper...');
    console.log('Tama√±o del archivo:', audioFile.size, 'bytes');
    console.log('Tipo de archivo:', audioFile.type);

    // Transcribir usando OpenAI Whisper
    const transcription = await openai.audio.transcriptions.create({
      file: file,
      model: 'whisper-1',
      language: 'es', // Espa√±ol
      response_format: 'text',
      temperature: 0.2, // Baja temperatura para mayor precisi√≥n
    });

    console.log('Transcripci√≥n completada:', transcription);

    if (!transcription || typeof transcription !== 'string' || transcription.trim().length === 0) {
      return NextResponse.json(
        { success: false, error: 'No se pudo transcribir el audio. Intenta hablar m√°s claro o verificar el micr√≥fono.' },
        { status: 400 }
      );
    }

    return NextResponse.json({
      success: true,
      text: transcription.trim()
    });

  } catch (error: unknown) {
    console.error('Error en transcripci√≥n:', error);
    
    // Manejar errores espec√≠ficos de OpenAI
    if (error && typeof error === 'object' && 'error' in error) {
      const openAiError = error as { error?: { type?: string }; status?: number };
      
      if (openAiError.error?.type === 'invalid_request_error') {
        return NextResponse.json(
          { success: false, error: 'Archivo de audio inv√°lido o demasiado largo' },
          { status: 400 }
        );
      }
      
      if (openAiError.status === 401) {
        return NextResponse.json(
          { success: false, error: 'Error de autenticaci√≥n con OpenAI' },
          { status: 500 }
        );
      }
    }

    return NextResponse.json(
      { 
        success: false, 
        error: 'Error al transcribir el audio. Por favor, intenta nuevamente.' 
      },
      { status: 500 }
    );
  }
}
