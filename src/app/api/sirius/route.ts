import { NextRequest, NextResponse } from 'next/server';

const OPENAI_API_KEY = process.env.OPENAI_API_KEY;

export async function POST(request: Request): Promise<Response> {
  try {
    console.log('ü§ñ SIRIUS API: Iniciando procesamiento...');
    
    const { message, userId, conversationHistory } = await request.json();
    
    console.log('üìù SIRIUS: Mensaje recibido:', message);
    console.log('üë§ SIRIUS: Usuario:', userId);

    if (!message || typeof message !== 'string') {
      return NextResponse.json(
        { error: 'Mensaje requerido' },
        { status: 400 }
      );
    }

    // Intentar obtener respuesta de OpenAI
    const response = await getOpenAIResponse(message, conversationHistory || []);
    
    console.log('‚úÖ SIRIUS: Respuesta generada');
    
    return NextResponse.json({
      success: true,
      response,
      timestamp: new Date().toISOString()
    });

  } catch (error) {
    console.error('‚ùå SIRIUS API: Error:', error);
    return NextResponse.json(
      { 
        error: 'Error interno del servidor',
        message: 'Lo siento, hubo un problema procesando tu consulta. Intenta de nuevo.'
      },
      { status: 500 }
    );
  }
}

async function getOpenAIResponse(message: string, conversationHistory: any[]): Promise<string> {
  if (!OPENAI_API_KEY) {
    throw new Error('OPENAI_API_KEY no configurada');
  }

  // Contexto especializado del laboratorio
  const systemPrompt = `Eres SIRIUS, un asistente de IA avanzado especializado en laboratorios de microorganismos y biotecnolog√≠a. 

üî¨ **Tu especialidad:**
- Microbiolog√≠a y biotecnolog√≠a avanzada
- Gesti√≥n inteligente de laboratorios de investigaci√≥n
- Procesos de inoculaci√≥n, cultivo y cosecha optimizados
- Control de calidad y an√°lisis predictivo
- Inventario inteligente y equipos de laboratorio
- An√°lisis de datos y tendencias

üìä **Datos del laboratorio que manejas:**
- Insumos y stock de materiales con predicci√≥n de necesidades
- Cepas bacterianas y microorganismos con seguimiento gen√©tico
- Procesos activos de inoculaci√≥n con optimizaci√≥n autom√°tica
- Registros de cosecha y producci√≥n con an√°lisis de rendimiento
- Bit√°cora inteligente de actividades del laboratorio
- Equipos con monitoreo predictivo y mantenimiento preventivo

üéØ **Tu personalidad como SIRIUS:**
- Asistente inteligente de √∫ltima generaci√≥n
- Experto t√©cnico con capacidades anal√≠ticas avanzadas
- Proactivo en optimizaci√≥n y mejora continua
- Capaz de an√°lisis predictivo y recomendaciones estrat√©gicas
- Comunicaci√≥n clara y profesional con toques de innovaci√≥n
- Enfocado en la excelencia cient√≠fica y eficiencia operativa

üí¨ **Instrucciones de conversaci√≥n:**
- Mant√©n un tono profesional pero accesible, como un cient√≠fico experto
- Proporciona an√°lisis detallados cuando sea relevante
- Sugiere optimizaciones y mejoras basadas en mejores pr√°cticas
- Ofrece insights y predicciones cuando sea apropiado
- Si no tienes datos espec√≠ficos, explica qu√© an√°lisis podr√≠as realizar con m√°s informaci√≥n
- Usa un enfoque cient√≠fico y basado en datos
- Incluye emojis relevantes para hacer la conversaci√≥n m√°s visual

Responde como SIRIUS, el asistente de IA m√°s avanzado para laboratorios, combinando experiencia t√©cnica con capacidades anal√≠ticas superiores.`;

  try {
    // Construir el historial de conversaci√≥n para OpenAI
    const messages = [
      {
        role: 'system',
        content: systemPrompt
      }
    ];

    // Agregar historial previo (√∫ltimos 10 mensajes para no exceder tokens)
    const recentHistory = conversationHistory.slice(-10);
    recentHistory.forEach((msg: {type: string; content: string}) => {
      messages.push({
        role: msg.type === 'user' ? 'user' : 'assistant',
        content: msg.content
      });
    });

    // Agregar mensaje actual
    messages.push({
      role: 'user',
      content: message
    });

    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${OPENAI_API_KEY}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'gpt-4o-mini', // Modelo m√°s r√°pido y conversacional
        messages: messages,
        max_tokens: 800,
        temperature: 0.8, // M√°s creatividad para conversaci√≥n natural
        presence_penalty: 0.6, // Evitar repetici√≥n
        frequency_penalty: 0.3,
        stream: false
      }),
    });

    if (!response.ok) {
      const errorData = await response.json();
      console.error('OpenAI API error:', errorData);
      throw new Error(`OpenAI API error: ${response.status} - ${errorData.error?.message || 'Error desconocido'}`);
    }

    const data = await response.json();
    const aiResponse = data.choices[0]?.message?.content;
    
    if (!aiResponse) {
      throw new Error('No se recibi√≥ respuesta v√°lida de OpenAI');
    }

    return aiResponse;
  } catch (error) {
    console.error('Error con OpenAI:', error);
    throw error;
  }
}
